{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from stereoVO.structures import StateBolts, VO_StateMachine\n",
    "from stereoVO.datasets import KittiDataset\n",
    "from stereoVO.configs import yaml_parser\n",
    "\n",
    "from stereoVO.geometry import (DetectionEngine, \n",
    "                               filter_matching_inliers, \n",
    "                               triangulate_points, \n",
    "                               filter_triangulated_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../../KITTI/KITTI_gray/dataset/sequences/00/'\n",
    "CONFIG_PATH =  '../configs/params.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialise the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = KittiDataset(PATH)\n",
    "\n",
    "dataset.intrinsic = dataset.camera_intrinsic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the Configs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = yaml_parser(CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialise the State**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_num = 0\n",
    "\n",
    "left_frame, right_frame, ground_truth = dataset[state_num]\n",
    "\n",
    "#initialise the state\n",
    "prevState = VO_StateMachine(state_num)\n",
    "\n",
    "#set frame state\n",
    "prevState.frames = left_frame, right_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Detction Engine, Matching and Triangulation for first frame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_engine = DetectionEngine(prevState.frames.left, prevState.frames.right, params)\n",
    "\n",
    "prevState.matchedPoints, prevState.keypoints, prevState.descriptors = detection_engine.get_matching_keypoints()\n",
    "\n",
    "prevState.inliers, mask_epipolar = filter_matching_inliers(prevState.matchedPoints.left,\n",
    "                                            prevState.matchedPoints.right,\n",
    "                                            dataset.intrinsic,\n",
    "                                            params)\n",
    "\n",
    "prevState.pts3D, reproj_error = triangulate_points(prevState.inliers.left,\n",
    "                                    prevState.inliers.right,\n",
    "                                    dataset.PL,\n",
    "                                    dataset.PR)\n",
    "\n",
    "args_triangulation = params.geometry.triangulation\n",
    "prevState.pts3D_Filter, maskTriangulationFilter, ratioFilter = filter_triangulated_points(prevState.pts3D, reproj_error, **args_triangulation)\n",
    "\n",
    "prevState.InliersFilter = prevState.inliers.left[maskTriangulationFilter], prevState.inliers.right[maskTriangulationFilter]\n",
    "prevState.ratioTriangulationFilter = ratioFilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialise the Second State and set it as currState**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_num = 1\n",
    "\n",
    "left_frame, right_frame, ground_truth = dataset[state_num]\n",
    "\n",
    "#initialise the state\n",
    "currState = VO_StateMachine(state_num)\n",
    "\n",
    "#set frame state\n",
    "currState.frames = left_frame, right_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_engine = DetectionEngine(currState.frames.left, currState.frames.right, params)\n",
    "\n",
    "currState.matchedPoints, currState.keypoints, currState.descriptors = detection_engine.get_matching_keypoints()\n",
    "\n",
    "currState.inliers, mask_epipolar = filter_matching_inliers(currState.matchedPoints.left,\n",
    "                                            currState.matchedPoints.right,\n",
    "                                            dataset.intrinsic,\n",
    "                                            params)\n",
    "\n",
    "currState.pts3D, reproj_error = triangulate_points(currState.inliers.left,\n",
    "                                    currState.inliers.right,\n",
    "                                    dataset.PL,\n",
    "                                    dataset.PR)\n",
    "\n",
    "args_triangulation = params.geometry.triangulation\n",
    "currState.pts3D_Filter, maskTriangulationFilter, ratioFilter = filter_triangulated_points(currState.pts3D, reproj_error, **args_triangulation)\n",
    "\n",
    "currState.InliersFilter = currState.inliers.left[maskTriangulationFilter], currState.inliers.right[maskTriangulationFilter]\n",
    "currState.ratioTriangulationFilter = ratioFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracker = TrackingEngine(prev_frames, curr_frames, prevState.InliersFilter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevFrames = prevState.frames\n",
    "currFrames = currState.frames\n",
    "prevInliers = prevState.InliersFilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Tracking from prev state to current state**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lk_params = dict(winSize  = (21, 21), \n",
    "                 maxLevel = 5,\n",
    "                 criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 30, 0.03))\n",
    "\n",
    "dist_x_y = lambda x,y:np.sqrt(np.sum((x - y)**2, axis=1))\n",
    "\n",
    "def feature_tracking(imageRef, imageCur, pointsRef):\n",
    "    \n",
    "    \"\"\"\n",
    "    To Do : Add docstring for the function here.\n",
    "    \"\"\"\n",
    "    \n",
    "    assert len(pointsRef.shape)==2 and pointsRef.shape[1]==2\n",
    "    \n",
    "    pointsRef = pointsRef.reshape(-1,1,2).astype('float32')\n",
    "    points_t0_t1, mask_t0_t1, err = cv2.calcOpticalFlowPyrLK(imageRef, imageCur, pointsRef, None, **lk_params)\n",
    "    \n",
    "    pointsRef = pointsRef.reshape(-1,2)\n",
    "    points_t0_t1 = points_t0_t1.reshape(-1,2)\n",
    "    mask_t0_t1 = mask_t0_t1.flatten().astype(bool)\n",
    "       \n",
    "#     pointsRef = pointsRef[mask_t0_t1]\n",
    "#     points_t0_t1 = points_t0_t1[mask_t0_t1]\n",
    "    \n",
    "    return pointsRef, points_t0_t1, mask_t0_t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointsFilterLeft, pointsTrackedLeft, maskTrackingLeft = feature_tracking(prevFrames.left,\n",
    "                                                                        currFrames.left,\n",
    "                                                                        prevInliers.left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointsFilterRight, pointsTrackedRight, maskTrackingRight = feature_tracking(prevFrames.right,\n",
    "                                                                           currFrames.right,\n",
    "                                                                           prevInliers.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joint index and select only good tracked points\n",
    "maskTracking = np.logical_and(maskTrackingLeft, maskTrackingRight)\n",
    "pointsTracked = StateBolts(pointsTrackedLeft[maskTracking], pointsTrackedRight[maskTracking])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-valid points from inliers filtered in prev state\n",
    "prevStateInliers = StateBolts(prevInliers.left[maskTracking], prevInliers.right[maskTracking])\n",
    "pts3D_TrackingFilter = prevState.pts3D_Filter[maskTracking]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(_, __ ) , mask_tracking_epipolar_left = filter_matching_inliers(prevStateInliers.left, pointsTracked.left, dataset.intrinsic, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(_, __ ) , mask_tracking_epipolar_right = filter_matching_inliers(prevStateInliers.right, pointsTracked.right, dataset.intrinsic, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_tracking_epipolar = np.logical_and(mask_tracking_epipolar_left, mask_tracking_epipolar_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "currState.pointsTracked = (pointsTracked.left[mask_tracking_epipolar], pointsTracked.right[mask_tracking_epipolar])\n",
    "prevState.inliersTrackingFilter =  (prevStateInliers.left[mask_tracking_epipolar], prevStateInliers.right[mask_tracking_epipolar])\n",
    "prevState.pts3D_TrackingFilter = pts3D_TrackingFilter[mask_tracking_epipolar]                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.71319816, -2.46841753, 10.40955676],\n",
       "       [-7.75243009, -2.42910212, 10.47811198],\n",
       "       [-7.62119461,  1.39321526, 10.45125536],\n",
       "       ...,\n",
       "       [ 3.69848948,  0.70925672,  7.35911711],\n",
       "       [ 3.73591638,  0.72400023,  7.37031955],\n",
       "       [ 3.75160447,  0.67838825,  7.31470665]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prevState.pts3D_TrackingFilter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**P3P Solver**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale of translation of camera     : 0.6764176064655109\n",
      "Solution obtained in P3P Iteration : 1\n",
      "Ratio of Inliers                   : 1.0\n"
     ]
    }
   ],
   "source": [
    "args_pnpSolver = params.geometry.pnpSolver\n",
    "\n",
    "\n",
    "for i in range(args_pnpSolver.numTrials):\n",
    "    \n",
    "    retval, r_vec, t_vec, idxPose = cv2.solvePnPRansac(prevState.pts3D_TrackingFilter,\n",
    "                                                       currState.pointsTracked.left,\n",
    "                                                       dataset.intrinsic,\n",
    "                                                       None,\n",
    "                                                       iterationsCount=args_pnpSolver.numTrials,\n",
    "                                                       reprojectionError=args_pnpSolver.reprojectionError,\n",
    "                                                       confidence=args_pnpSolver.confidence,\n",
    "                                                       flags=cv2.SOLVEPNP_P3P)\n",
    "    \n",
    "    \n",
    "    r_mat, _ = cv2.Rodrigues(r_vec)\n",
    "    \n",
    "    # r_vec and t_vec obtained are in camera coordinate frames\n",
    "    # we need to convert these matrix in world coordinates system\n",
    "    # or we need to transforms the matrix from currState to prevState\n",
    "    r_mat = r_mat.T\n",
    "    t_vec = -r_mat.T @ t_vec\n",
    "    \n",
    "    idxPose = idxPose.flatten().astype(bool)\n",
    "    \n",
    "    ratio = sum(idxPose)/len(idxPose)\n",
    "    scale = np.linalg.norm(t_vec)\n",
    "    \n",
    "    if scale<args_pnpSolver.deltaT and ratio>args_pnpSolver.minRatio:\n",
    "        print(\"Scale of translation of camera     : {}\".format(scale))\n",
    "        print(\"Solution obtained in P3P Iteration : {}\".format(i+1))\n",
    "        print(\"Ratio of Inliers                   : {}\".format(ratio))\n",
    "        break\n",
    "    else:\n",
    "        print(\"Warning : Max Iter : {} reached, still large position delta produced\".format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# according to the Vo tutorial\n",
    "# C_n = C_n-1 * dTn-1\n",
    "# where the dTn-1 is in the coordinate frame of the second camera\n",
    "# importan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimisation=True\n",
    "\n",
    "if optimisation:\n",
    "    \n",
    "    # Convert the matrix from world co\n",
    "    r_mat \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv",
   "language": "python",
   "name": "opencv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
